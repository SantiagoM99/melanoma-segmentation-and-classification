{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains the different models that will be compared using the data from the ISIC 2017 challenge. The models that will be trained are:\n",
    "\n",
    "- Unet (Baseline)\n",
    "- Attention Unet\n",
    "- R2Unet\n",
    "- Attention R2Unet\n",
    "- TransUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.3.0 torchaudio==2.3.0 torchvision==0.18.0\n",
    "# !pip install albumentations numpy pandas scikit_learn kaggle\n",
    "# !pip install resnest geffnet opencv-python pretrainedmodels tqdm Pillow packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -i https://test.pypi.org/simple/ melanoma-segmentation==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_setting import CONFIG\n",
    "from models.unet import UNet\n",
    "from models.attention_unet import AttUNet\n",
    "from models.trans_unet import TransUNet\n",
    "from results.plots import plot_img_mask_pred\n",
    "from utils.preparation_tools import prepare_datasets\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = CONFIG[\"base_dir\"]\n",
    "image_folder = CONFIG[\"image_folder\"]\n",
    "gt_folder = CONFIG[\"gt_folder\"]\n",
    "model_name = CONFIG[\"model_name\"]\n",
    "split_train = CONFIG[\"split_train\"]\n",
    "split_val = CONFIG[\"split_val\"]\n",
    "split_test = CONFIG[\"split_test\"]\n",
    "image_size = 256\n",
    "batch_size = CONFIG[\"batch_size\"]\n",
    "model_path = CONFIG[\"model_path\"]\n",
    "device = CONFIG[\"device\"]\n",
    "\n",
    "CONFIG_FINAL = CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive, files\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "CONFIG_DRIVE = CONFIG.copy()\n",
    "#CONFIG_DRIVE[\"base_dir\"] = \"/content/drive/MyDrive/melanoma-segmentation-and-classification/data/\"\n",
    "CONFIG_DRIVE[\"image_folder\"] = image_folder\n",
    "CONFIG_DRIVE[\"gt_folder\"] = gt_folder\n",
    "CONFIG_DRIVE[\"model_name\"] = model_name\n",
    "CONFIG_DRIVE[\"split_train\"] = split_train\n",
    "CONFIG_DRIVE[\"split_val\"] = split_val\n",
    "CONFIG_DRIVE[\"split_test\"] = split_test\n",
    "CONFIG_DRIVE['image_size'] = image_size\n",
    "CONFIG_DRIVE[\"batch_size\"] = batch_size\n",
    "CONFIG_DRIVE[\"model_path\"] = model_path\n",
    "CONFIG_DRIVE[\"device\"] = device\n",
    "CONFIG_FINAL = CONFIG_DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieve the image and ground truth paths change\n",
    "train_dataset, val_dataset, test_dataset = prepare_datasets(CONFIG_FINAL, train_transform_type=\"train\")\n",
    "\n",
    "# Get the train test and validation dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_mask_pred(train_dataset)\n",
    "plot_img_mask_pred(val_dataset)\n",
    "plot_img_mask_pred(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() >= 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs.\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "# Check if the model is on the GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print amount of images in each dataset\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} images\")\n",
    "print(f\"Val dataset: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Define Optimizer and Loss Function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define early stopping parameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "min_delta = 1e-4  # Minimum improvement in the loss to be considered\n",
    "best_loss = float('inf')\n",
    "counter = 0  # Count epochs with no improvement\n",
    "max_epochs = 50  # Maximum number of epochs to run\n",
    "\n",
    "# Track the start time for timed stopping (if needed)\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (images, masks) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch} - Average Loss: {avg_loss}\")\n",
    "\n",
    "    # Check for early stopping based on loss improvement\n",
    "    if avg_loss < best_loss - min_delta:\n",
    "        best_loss = avg_loss\n",
    "        counter = 0  # Reset counter if there's improvement\n",
    "        print(f\"Loss improved to {best_loss}, resetting patience counter.\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement in loss. Patience counter: {counter}/{patience}\")\n",
    "\n",
    "    # If patience is exceeded, stop training\n",
    "    if counter >= patience:\n",
    "        print(f\"Stopping early after {epoch} epochs due to lack of improvement.\")\n",
    "        break\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"unet_256_aug.pth\")\n",
    "# files.download(\"attunet_512_aug.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "# import time\n",
    "\n",
    "# # Define Optimizer and Loss Function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = lambda y_pred, y_true: nn.BCEWithLogitsLoss()(y_pred, y_true) + DiceLoss()(y_pred, y_true)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# # Define early stopping parameters\n",
    "# patience = 3  # Number of epochs to wait for improvement\n",
    "# min_delta = 1e-4  # Minimum improvement in the loss to be considered\n",
    "# best_val_loss = float('inf')\n",
    "# counter = 0  # Count epochs with no improvement\n",
    "# max_epochs = 20  # Maximum number of epochs to run\n",
    "\n",
    "# # Track the start time for timed stopping (if needed)\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(max_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for i, (images, masks) in enumerate(train_dataloader):\n",
    "#         images = images.to(device)\n",
    "#         masks = masks.to(device).float()\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Apply gradient clipping\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "#     # Average loss for the epoch\n",
    "#     avg_train_loss = epoch_loss / len(train_dataloader)\n",
    "#     print(f\"Epoch {epoch} - Average Training Loss: {avg_train_loss}\")\n",
    "\n",
    "#     # Validation phase\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_loss = 0\n",
    "#         for images, masks in val_dataloader:\n",
    "#             images = images.to(device)\n",
    "#             masks = masks.to(device).float()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, masks)\n",
    "#             val_loss += loss.item()\n",
    "#         avg_val_loss = val_loss / len(val_dataloader)\n",
    "#         print(f\"Epoch {epoch} - Average Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "#     # Check for early stopping based on validation loss improvement\n",
    "#     scheduler.step(avg_val_loss)  # Adjust learning rate if validation loss plateaus\n",
    "\n",
    "#     if avg_val_loss < best_val_loss - min_delta:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         counter = 0  # Reset counter if there's improvement\n",
    "#         print(f\"Validation Loss improved to {best_val_loss}, resetting patience counter.\")\n",
    "#         torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         print(f\"No improvement in validation loss. Patience counter: {counter}/{patience}\")\n",
    "\n",
    "#     # If patience is exceeded, stop training\n",
    "#     if counter >= patience:\n",
    "#         print(f\"Stopping early after {epoch} epochs due to lack of improvement.\")\n",
    "#         break\n",
    "\n",
    "# # Save the final model\n",
    "# torch.save(model.state_dict(), \"final_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
